{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNRXzdklRf3HjbzlAzJbSrj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karthik111/video_anomaly_detection/blob/master/notebook/i3d_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "vItkUJ_dWel8",
        "outputId": "c2befc7e-5f60-417f-cceb-dd8bfd8acf84"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "load() got an unexpected keyword argument 'context'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-723707e5e3c1>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load I3D model from TensorFlow Hub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mi3d_model_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://tfhub.dev/deepmind/i3d-kinetics-400/1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mi3d_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi3d_model_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munverified_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: load() got an unexpected keyword argument 'context'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import cv2\n",
        "import ssl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import cv2\n",
        "import ssl\n",
        "\n",
        "unverified_context = ssl._create_unverified_context()"
      ],
      "metadata": {
        "id": "z-EA4QwdWjRZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load I3D model from TensorFlow Hub\n",
        "i3d_model_url = \"https://tfhub.dev/deepmind/i3d-kinetics-400/1\"\n"
      ],
      "metadata": {
        "id": "I46UAqURWwhx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i3d_model = hub.load(i3d_model_url)"
      ],
      "metadata": {
        "id": "Qzrud9WAXKb0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess video frames for I3D model\n",
        "def preprocess_video_frame(frame):\n",
        "    frame = cv2.resize(frame, (224, 224))\n",
        "    frame = frame[..., ::-1]  # Convert BGR to RGB\n",
        "    return frame\n"
      ],
      "metadata": {
        "id": "ptkVhkvpXRc9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract features from video frames\n",
        "def extract_video_features(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    features = []\n",
        "    print(f\"Extracting features from {frame_count} frames...\")\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Preprocess frame for I3D input\n",
        "        frame = preprocess_video_frame(frame)\n",
        "\n",
        "        # Add batch dimension and normalize pixel values\n",
        "        frame = np.expand_dims(frame.astype(np.float32) / 255.0, axis=0)\n",
        "\n",
        "        # Extract features from the frame using I3D model\n",
        "        frame_features = i3d_model(frame)['default']\n",
        "        features.append(np.squeeze(frame_features))\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(features)"
      ],
      "metadata": {
        "id": "TZZxBeNuX3_9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: extract features from a video\n",
        "video_path = 'output.mp4'\n",
        "video_features = extract_video_features(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "KY68_DjKX_qp",
        "outputId": "150707d4-a98b-4c39-838d-ff15d1fe5f57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from 32 frames...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'AutoTrackable' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7f0ed711a4dd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example usage: extract features from a video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'output.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvideo_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_video_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-e21b757d8df3>\u001b[0m in \u001b[0;36mextract_video_features\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Extract features from the frame using I3D model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mframe_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi3d_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'AutoTrackable' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "features = []\n",
        "print(f\"Extracting features from {frame_count} frames...\")\n",
        "ret, frame = cap.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8ytnBAtYIXZ",
        "outputId": "4bb89463-4b79-42dc-9dde-b652c31d20fd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from 32 frames...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frame.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3rDI-ykYI4Z",
        "outputId": "568b1a45-1710-4ebe-b5cf-a76182c5a956"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1080, 1620, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frame = preprocess_video_frame(frame)\n",
        "\n",
        "# Add batch dimension and normalize pixel values\n",
        "frame = np.expand_dims(frame.astype(np.float32) / 255.0, axis=0)"
      ],
      "metadata": {
        "id": "QQ-hJzS5ZgaX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = hub.KerasLayer(i3d_model_url)"
      ],
      "metadata": {
        "id": "-_y7c1cocMTs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m?"
      ],
      "metadata": {
        "id": "ROWX_uZXfCOE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame = tf.expand_dims(frame, axis=0)"
      ],
      "metadata": {
        "id": "0hiil_uBdcVZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zd-f2MleFPu",
        "outputId": "37c01382-c0cc-42fc-b0df-332b6daacac0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 1, 224, 224, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = m(frame)"
      ],
      "metadata": {
        "id": "tqZQs-ggdeE4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrY2GbIrdhdU",
        "outputId": "d0a889b7-28e7-4edd-8a17-071757bea455"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 400])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "400*32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXVokGiXeKJ3",
        "outputId": "9dc6884e-b708-4efd-d93b-6376f58ce6d3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12800"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "400*16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQaY0ZZEeaHg",
        "outputId": "f465d529-1e04-477d-8a1c-7dfc4f7aa622"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6400"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p22MeIdSeczZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}